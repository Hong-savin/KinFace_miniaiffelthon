{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "bbIShvj7HuVa",
        "outputId": "fa5f59c1-06ae-4e95-a54f-78a854d2c09e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://d727419dd07b942d67.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d727419dd07b942d67.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# !pip install deepface opencv-python gradio scikit-image dlib\n",
        "\n",
        "import gradio as gr\n",
        "import cv2\n",
        "import numpy as np\n",
        "import dlib\n",
        "from PIL import Image\n",
        "from deepface import DeepFace\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# OpenCV 얼굴 검출기 초기화\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "# 가중치 설정\n",
        "weights = {\n",
        "    \"feature_distribution\": 0.2,  # 이목구비의 분포\n",
        "    \"eye_color\": 0.05,            # 눈동자 색\n",
        "    \"nose_shape\": 0.15,            # 코의 모양\n",
        "    \"mouth_shape\": 0.15,           # 입의 모양\n",
        "    \"eye_position_ratio\": 0.15,    # 눈 위치 비율\n",
        "    \"nose_position_ratio\": 0.15,   # 코 위치 비율\n",
        "    \"mouth_position_ratio\": 0.15  # 입 위치 비율\n",
        "}\n",
        "# 얼굴 검출 함수\n",
        "def detect_face_opencv(image):\n",
        "    image_np = np.array(image.convert(\"RGB\"))\n",
        "    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "    return len(faces) > 0\n",
        "\n",
        "# 얼굴 인식 상태 확인 함수\n",
        "def check_face(image, role):\n",
        "    if not detect_face_opencv(image):\n",
        "        return f\"{role}: 얼굴 인식이 불가합니다.\", False\n",
        "    return f\"{role}: 얼굴 인식 성공!\", True\n",
        "\n",
        "# 얼굴 인식 결과 취합\n",
        "def update_recognition_status(father_img, mother_img, child_img, sibling_files):\n",
        "    roles = [\"Father\", \"Mother\", \"Child\"]\n",
        "    images = [father_img, mother_img, child_img]\n",
        "    sibling_images = [Image.open(f) for f in sibling_files] if sibling_files else []\n",
        "\n",
        "    all_images = images + sibling_images\n",
        "    all_roles = roles + [f\"Sibling {i+1}\" for i in range(len(sibling_images))]\n",
        "    messages = []\n",
        "    success = True\n",
        "\n",
        "    for img, role in zip(all_images, all_roles):\n",
        "        if img is not None:\n",
        "            message, detected = check_face(img, role)\n",
        "            messages.append(message)\n",
        "            if not detected:\n",
        "                success = False\n",
        "\n",
        "    return \"\\n\".join(messages), success\n",
        "\n",
        "# 코사인 유사도 계산 함수\n",
        "def calculate_cosine_similarity(embedding1, embedding2):\n",
        "    embedding1 = np.array(embedding1).reshape(1, -1)\n",
        "    embedding2 = np.array(embedding2).reshape(1, -1)\n",
        "    return cosine_similarity(embedding1, embedding2)[0][0]\n",
        "\n",
        "# RGB 유사도 계산 함수\n",
        "def calculate_rgb_similarity(img1, img2):\n",
        "    \"\"\"\n",
        "    두 이미지의 평균 RGB 유사도를 계산합니다.\n",
        "    Args:\n",
        "        img1, img2: numpy 배열 (RGB 형식)\n",
        "    Returns:\n",
        "        float: RGB 유사도 (0 ~ 1)\n",
        "    \"\"\"\n",
        "    # 이미지를 RGB로 변환\n",
        "    if img1.shape[-1] != 3 or img2.shape[-1] != 3:\n",
        "        raise ValueError(\"이미지가 RGB 형식이 아닙니다.\")\n",
        "\n",
        "    # 이미지의 평균 RGB 값 계산\n",
        "    avg_rgb1 = np.mean(img1, axis=(0, 1))\n",
        "    avg_rgb2 = np.mean(img2, axis=(0, 1))\n",
        "\n",
        "    # RGB 유사도 계산\n",
        "    diff = np.linalg.norm(avg_rgb1 - avg_rgb2)\n",
        "    return 1 - (diff / np.sqrt(3 * (255 ** 2)))  # 0~1 범위로 정규화\n",
        "\n",
        "\n",
        "# SSIM 유사도 계산\n",
        "def calculate_ssim_similarity(image1, image2, target_size=(224, 224)):\n",
        "    \"\"\"\n",
        "    두 이미지 간 구조적 유사도 (SSIM)를 계산합니다.\n",
        "    Args:\n",
        "        image1, image2: numpy 배열 (BGR 형식)\n",
        "        target_size: SSIM 계산을 위한 리사이즈 크기\n",
        "    Returns:\n",
        "        float: SSIM 값\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 이미지를 동일한 크기로 리사이즈\n",
        "        resized_img1 = cv2.resize(image1, target_size, interpolation=cv2.INTER_AREA)\n",
        "        resized_img2 = cv2.resize(image2, target_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "        # 흑백 변환\n",
        "        gray1 = cv2.cvtColor(resized_img1, cv2.COLOR_BGR2GRAY)\n",
        "        gray2 = cv2.cvtColor(resized_img2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # SSIM 계산\n",
        "        return ssim(gray1, gray2)\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"SSIM 계산 중 오류 발생: {str(e)}\")\n",
        "\n",
        "def landmarks_to_numpy(landmarks):\n",
        "    \"\"\"\n",
        "    Dlib 랜드마크 객체를 NumPy 배열로 변환합니다.\n",
        "\n",
        "    Args:\n",
        "        landmarks: Dlib의 full_object_detection 객체\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: 랜드마크 좌표 배열 (N x 2)\n",
        "    \"\"\"\n",
        "    if not isinstance(landmarks, dlib.full_object_detection):\n",
        "        raise TypeError(\"Input must be a dlib.full_object_detection object.\")\n",
        "\n",
        "    num_points = landmarks.num_parts\n",
        "    points_array = np.array([[landmarks.part(i).x, landmarks.part(i).y] for i in range(num_points)])\n",
        "    return points_array\n",
        "\n",
        "def calculate_lip_curvature_similarity(landmarks1, landmarks2):\n",
        "    \"\"\"\n",
        "    두 얼굴의 입술 랜드마크 기반 곡률 유사도를 계산합니다.\n",
        "\n",
        "    Args:\n",
        "        landmarks1: 첫 번째 얼굴의 랜드마크 배열 (numpy 배열)\n",
        "        landmarks2: 두 번째 얼굴의 랜드마크 배열 (numpy 배열)\n",
        "\n",
        "    Returns:\n",
        "        float: 입술 곡률 유사도 (0 ~ 1 범위)\n",
        "    \"\"\"\n",
        "    # 입력 데이터 검증\n",
        "    if landmarks1.shape[0] < 60 or landmarks2.shape[0] < 60:\n",
        "        raise ValueError(\"Landmark arrays must have at least 60 points.\")\n",
        "\n",
        "    # 입술 랜드마크 좌표 (48~59번 점)\n",
        "    top_curve_diff = np.linalg.norm(landmarks1[48:54] - landmarks2[48:54], axis=1).mean()\n",
        "    bottom_curve_diff = np.linalg.norm(landmarks1[54:60] - landmarks2[54:60], axis=1).mean()\n",
        "\n",
        "    # 정규화 (최대 좌표값 기준)\n",
        "    max_possible_diff = 1000  # 예상 가능한 최대 좌표 차이\n",
        "    normalized_top = top_curve_diff / max_possible_diff\n",
        "    normalized_bottom = bottom_curve_diff / max_possible_diff\n",
        "\n",
        "    # 유사도 계산 (0 ~ 1 범위)\n",
        "    similarity = 1 - (normalized_top + normalized_bottom) / 2\n",
        "\n",
        "    # 비정상 값 처리\n",
        "    similarity = max(0, min(similarity, 1))  # 유사도를 0~1로 제한\n",
        "    return similarity\n",
        "\n",
        "def calculate_position_ratio_similarity(landmarks1, landmarks2, position_index, max_diff=0.2):\n",
        "    \"\"\"\n",
        "    랜드마크를 기반으로 특정 부위의 위치 비율 유사도를 계산합니다.\n",
        "\n",
        "    Args:\n",
        "        landmarks1 (numpy.ndarray): 첫 번째 얼굴의 랜드마크 배열.\n",
        "        landmarks2 (numpy.ndarray): 두 번째 얼굴의 랜드마크 배열.\n",
        "        position_index (int): 비교할 랜드마크 포인트의 인덱스.\n",
        "        max_diff (float): 최대 허용 비율 차이 (기본값: 0.2).\n",
        "\n",
        "    Returns:\n",
        "        float: 0~1 범위의 유사도 점수.\n",
        "    \"\"\"\n",
        "    def position_ratio(landmarks, position_index):\n",
        "        forehead = landmarks[27]  # 이마 중앙점\n",
        "        chin = landmarks[8]  # 턱 중앙점\n",
        "        face_length = np.linalg.norm(forehead - chin)\n",
        "        if face_length == 0:\n",
        "            raise ValueError(\"Invalid face length: forehead and chin landmarks are identical.\")\n",
        "        position = landmarks[position_index]\n",
        "        return (position[1] - forehead[1]) / face_length\n",
        "\n",
        "    ratio1 = position_ratio(landmarks1, position_index)\n",
        "    ratio2 = position_ratio(landmarks2, position_index)\n",
        "    diff = abs(ratio1 - ratio2)\n",
        "    similarity = 1 - (diff / max_diff)\n",
        "    return max(0, min(similarity, 1))\n",
        "\n",
        "\n",
        "def calculate_eye_position_ratio_similarity(landmarks1, landmarks2, max_diff=0.2):\n",
        "    \"\"\"\n",
        "    두 얼굴의 눈 위치 비율 유사도를 계산합니다.\n",
        "\n",
        "    Args:\n",
        "        landmarks1 (numpy.ndarray): 첫 번째 얼굴의 랜드마크 배열.\n",
        "        landmarks2 (numpy.ndarray): 두 번째 얼굴의 랜드마크 배열.\n",
        "        max_diff (float): 최대 허용 비율 차이 (기본값: 0.2).\n",
        "\n",
        "    Returns:\n",
        "        float: 0~1 범위의 유사도 점수.\n",
        "    \"\"\"\n",
        "    return calculate_position_ratio_similarity(landmarks1, landmarks2, position_index=36, max_diff=max_diff)\n",
        "\n",
        "\n",
        "def calculate_nose_position_ratio_similarity(landmarks1, landmarks2, max_diff=0.2):\n",
        "    \"\"\"\n",
        "    두 얼굴의 코 위치 비율 유사도를 계산합니다.\n",
        "\n",
        "    Args:\n",
        "        landmarks1 (numpy.ndarray): 첫 번째 얼굴의 랜드마크 배열.\n",
        "        landmarks2 (numpy.ndarray): 두 번째 얼굴의 랜드마크 배열.\n",
        "        max_diff (float): 최대 허용 비율 차이 (기본값: 0.2).\n",
        "\n",
        "    Returns:\n",
        "        float: 0~1 범위의 유사도 점수.\n",
        "    \"\"\"\n",
        "    return calculate_position_ratio_similarity(landmarks1, landmarks2, position_index=30, max_diff=max_diff)\n",
        "\n",
        "\n",
        "def calculate_mouth_position_ratio_similarity(landmarks1, landmarks2, max_diff=0.2):\n",
        "    \"\"\"\n",
        "    두 얼굴의 입 위치 비율 유사도를 계산합니다.\n",
        "\n",
        "    Args:\n",
        "        landmarks1 (numpy.ndarray): 첫 번째 얼굴의 랜드마크 배열.\n",
        "        landmarks2 (numpy.ndarray): 두 번째 얼굴의 랜드마크 배열.\n",
        "        max_diff (float): 최대 허용 비율 차이 (기본값: 0.2).\n",
        "\n",
        "    Returns:\n",
        "        float: 0~1 범위의 유사도 점수.\n",
        "    \"\"\"\n",
        "    return calculate_position_ratio_similarity(landmarks1, landmarks2, position_index=51, max_diff=max_diff)\n",
        "\n",
        "\n",
        "# 유사도 계산 함수\n",
        "def calculate_similarity(father_img, mother_img, child_img, sibling_files):\n",
        "    if not (father_img and mother_img and child_img):\n",
        "        return \"모든 필수 이미지를 업로드하세요.\"\n",
        "\n",
        "    sibling_images = [Image.open(f) for f in sibling_files] if sibling_files else []\n",
        "\n",
        "    # 얼굴 인식 상태 확인\n",
        "    messages, success = update_recognition_status(father_img, mother_img, child_img, sibling_files)\n",
        "    if not success:\n",
        "        return f\"{messages}\\n\\n유사도 측정을 할 수 없습니다.\"\n",
        "\n",
        "    try:\n",
        "        # Dlib 랜드마크 감지를 위한 초기화\n",
        "        detector = dlib.get_frontal_face_detector()\n",
        "        predictor = dlib.shape_predictor(\"/content/drive/My Drive/shape_predictor_68_face_landmarks.dat\")\n",
        "\n",
        "        def get_landmarks(img, role):\n",
        "            \"\"\"이미지에서 랜드마크를 감지합니다.\"\"\"\n",
        "            img_array = np.array(img.convert(\"RGB\"))\n",
        "            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
        "            faces = detector(gray)\n",
        "            if len(faces) == 0:\n",
        "                return None\n",
        "            landmarks = predictor(gray, faces[0])\n",
        "            return landmarks_to_numpy(landmarks)\n",
        "\n",
        "        # 랜드마크 저장\n",
        "        landmarks_detected = {\n",
        "            \"Father\": get_landmarks(father_img, \"Father\"),\n",
        "            \"Mother\": get_landmarks(mother_img, \"Mother\"),\n",
        "            \"Child\": get_landmarks(child_img, \"Child\"),\n",
        "        }\n",
        "        for i, sibling_img in enumerate(sibling_images):\n",
        "            landmarks_detected[f\"Sibling {i+1}\"] = get_landmarks(sibling_img, f\"Sibling {i+1}\")\n",
        "\n",
        "        # DeepFace 기반 임베딩 생성\n",
        "        def get_embedding(img):\n",
        "            img_array = np.array(img.convert(\"RGB\"))\n",
        "            if img_array.size == 0:\n",
        "                raise ValueError(\"이미지가 비어 있습니다.\")\n",
        "            return DeepFace.represent(img_path=img_array, model_name=\"VGG-Face\", enforce_detection=False)[0][\"embedding\"]\n",
        "\n",
        "        embeddings = {\n",
        "            \"Father\": get_embedding(father_img),\n",
        "            \"Mother\": get_embedding(mother_img),\n",
        "            \"Child\": get_embedding(child_img),\n",
        "        }\n",
        "        for i, sibling_img in enumerate(sibling_images):\n",
        "            embeddings[f\"Sibling {i+1}\"] = get_embedding(sibling_img)\n",
        "\n",
        "        # 메트릭 기반 유사도 계산\n",
        "        similarities = {}\n",
        "\n",
        "        def calculate_similarities(role1, role2, img1, img2):\n",
        "            \"\"\"두 역할(role1, role2) 간 유사도를 계산합니다.\"\"\"\n",
        "            img1_array = np.array(img1.convert(\"RGB\"))\n",
        "            img2_array = np.array(img2.convert(\"RGB\"))\n",
        "\n",
        "            if landmarks_detected[role1] is not None and landmarks_detected[role2] is not None:\n",
        "                lip_similarity = calculate_lip_curvature_similarity(\n",
        "                    landmarks_detected[role1], landmarks_detected[role2]\n",
        "                )\n",
        "                eye_pos_similarity = calculate_eye_position_ratio_similarity(\n",
        "                    landmarks_detected[role1], landmarks_detected[role2]\n",
        "                )\n",
        "                nose_pos_similarity = calculate_nose_position_ratio_similarity(\n",
        "                    landmarks_detected[role1], landmarks_detected[role2]\n",
        "                )\n",
        "                mouth_pos_similarity = calculate_mouth_position_ratio_similarity(\n",
        "                    landmarks_detected[role1], landmarks_detected[role2]\n",
        "                )\n",
        "            else:\n",
        "                lip_similarity = eye_pos_similarity = nose_pos_similarity = mouth_pos_similarity = 0\n",
        "\n",
        "            similarities[f\"{role1}-{role2}\"] = {\n",
        "                \"feature_distribution\": calculate_cosine_similarity(\n",
        "                    embeddings[role1], embeddings[role2]\n",
        "                ),\n",
        "                \"eye_color\": calculate_rgb_similarity(\n",
        "                    img1_array, img2_array\n",
        "                ),\n",
        "                \"nose_shape\": calculate_ssim_similarity(\n",
        "                    img1_array, img2_array, target_size=(224, 224)\n",
        "                ),\n",
        "                \"mouth_shape\": lip_similarity,\n",
        "                \"eye_position_ratio\": eye_pos_similarity,\n",
        "                \"nose_position_ratio\": nose_pos_similarity,\n",
        "                \"mouth_position_ratio\": mouth_pos_similarity,\n",
        "            }\n",
        "\n",
        "        # 관계별 유사도 계산\n",
        "        calculate_similarities(\"Father\", \"Child\", father_img, child_img)\n",
        "        calculate_similarities(\"Mother\", \"Child\", mother_img, child_img)\n",
        "        for i, sibling_img in enumerate(sibling_images):\n",
        "            calculate_similarities(f\"Sibling {i+1}\", \"Child\", sibling_img, child_img)\n",
        "\n",
        "        # 가중치 기반 최종 유사도 계산\n",
        "        def calculate_weighted_similarity(metrics):\n",
        "            return sum(weights[key] * value for key, value in metrics.items() if key in weights)\n",
        "\n",
        "        # 유사도 결과 메시지 생성\n",
        "        def generate_similarity_message(similarity_score):\n",
        "            percentage = similarity_score * 100\n",
        "            if percentage > 60:\n",
        "                return \"동일인 아닌가요?\"\n",
        "            elif 50 <= percentage <= 60:\n",
        "                return \"붕어빵입니다\"\n",
        "            elif 40 <= percentage < 50:\n",
        "                return \"아주 닮았어요\"\n",
        "            elif 30 <= percentage < 40:\n",
        "                return \"닮았어요\"\n",
        "            elif 20 <= percentage < 30:\n",
        "                return \"잘 모르겠는데요?\"\n",
        "            elif 10 <= percentage < 20:\n",
        "                return \"딱히 안 닮았는데요?\"\n",
        "            else:\n",
        "                return \"유전자 검사 해봐요!\"\n",
        "\n",
        "        # 최종 결과\n",
        "        results = []\n",
        "        for role, img in [(\"Father\", father_img), (\"Mother\", mother_img)] + [\n",
        "            (f\"Sibling {i+1}\", sibling_img) for i, sibling_img in enumerate(sibling_images)\n",
        "        ]:\n",
        "            role_similarity = calculate_weighted_similarity(similarities[f\"{role}-Child\"])\n",
        "            similarity_message = generate_similarity_message(role_similarity)\n",
        "            results.append(f\"{role}: {role_similarity * 100:.2f}% 닮았습니다. {similarity_message}\")\n",
        "\n",
        "        return \"\\n\".join(results)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"유사도 계산 중 오류 발생: {str(e)}\"\n",
        "\n",
        "# Gradio UI 구성\n",
        "title = \"가족 유사도 분석\"\n",
        "description = \"사진을 업로드하면 얼굴 인식 결과가 즉시 표시됩니다. 유사도 분석 버튼을 눌러 결과를 확인하세요.\"\n",
        "\n",
        "with gr.Blocks() as interface:\n",
        "    gr.Markdown(f\"# {title}\")\n",
        "    gr.Markdown(description)\n",
        "\n",
        "    with gr.Row():\n",
        "        father_img = gr.Image(label=\"Father 사진 업로드\", type=\"pil\")\n",
        "        mother_img = gr.Image(label=\"Mother 사진 업로드\", type=\"pil\")\n",
        "        child_img = gr.Image(label=\"Child 사진 업로드\", type=\"pil\")\n",
        "\n",
        "    sibling_upload = gr.File(label=\"Sibling 사진 업로드 (선택)\", file_types=[\".jpg\", \".png\"], file_count=\"multiple\")\n",
        "    sibling_gallery = gr.Gallery(label=\"Sibling 사진 미리보기\", show_label=True, elem_id=\"sibling-gallery\")\n",
        "    recognition_status = gr.Textbox(label=\"얼굴 인식 결과\", interactive=False)\n",
        "    analyze_button = gr.Button(\"유사도 분석\")\n",
        "    similarity_results = gr.Textbox(label=\"유사도 분석 결과\", interactive=False)\n",
        "\n",
        "    # Sibling 미리보기 업데이트 함수\n",
        "    def update_sibling_gallery(sibling_files):\n",
        "        if sibling_files:\n",
        "            return [Image.open(f) for f in sibling_files]\n",
        "        return []\n",
        "\n",
        "    # 즉시 업데이트: 얼굴 인식 상태\n",
        "    def immediate_check_and_analyze(father_img, mother_img, child_img, sibling_files):\n",
        "        messages, _ = update_recognition_status(father_img, mother_img, child_img, sibling_files)\n",
        "        return messages\n",
        "\n",
        "    inputs = [father_img, mother_img, child_img, sibling_upload]\n",
        "    father_img.change(fn=immediate_check_and_analyze, inputs=inputs, outputs=recognition_status)\n",
        "    mother_img.change(fn=immediate_check_and_analyze, inputs=inputs, outputs=recognition_status)\n",
        "    child_img.change(fn=immediate_check_and_analyze, inputs=inputs, outputs=recognition_status)\n",
        "    sibling_upload.upload(fn=immediate_check_and_analyze, inputs=inputs, outputs=recognition_status)\n",
        "    sibling_upload.upload(fn=update_sibling_gallery, inputs=sibling_upload, outputs=sibling_gallery)\n",
        "\n",
        "    analyze_button.click(fn=calculate_similarity, inputs=inputs, outputs=similarity_results)\n",
        "\n",
        "interface.launch(share=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HKtOLavaH03c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
